{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "least-music",
   "metadata": {},
   "source": [
    "(https://www.kaggle.com/c/ashrae-energy-prediction/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-scope",
   "metadata": {},
   "source": [
    "# ASRAE - Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informal-ribbon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pmdarima version: 1.8.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly as plt\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import glob\n",
    "\n",
    "import pandas_profiling as ppf\n",
    "import sweetviz as sv\n",
    "import missingno as msno\n",
    "\n",
    "import pprint\n",
    "import datetime\n",
    "from math import sqrt\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from prophet import Prophet\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "import pmdarima as pm\n",
    "from pmdarima import model_selection\n",
    "from pmdarima import pipeline\n",
    "from pmdarima import preprocessing as ppc\n",
    "from pmdarima import arima\n",
    "from pmdarima.arima import ndiffs\n",
    "from pmdarima.arima import ADFTest\n",
    "\n",
    "print(\"pmdarima version: %s\" % pm.__version__)\n",
    "\n",
    "import tools as tl\n",
    "\n",
    "sns.set(rc={'figure.figsize':(30,20)})\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "sns.set(font_scale = 2)\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "civic-guinea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.2\n"
     ]
    }
   ],
   "source": [
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "harmful-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"matplotlib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "super-thong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Mike\\\\Google Drive\\\\Code\\\\Springboard_Capstone_Energy'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8519e6-1f19-4a32-a3b9-2a1831cd2bc5",
   "metadata": {},
   "source": [
    "## See Statistics written for each file (building-meter) combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "innovative-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See Building Statistics for missing data\n",
    "df_stats = pd.read_csv('.//data_clean//building_reading_stats.csv')\n",
    "# Keep only data that has at least 50 % of it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5b45a65-189e-43ae-8382-8147f24904b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1767 entries, 0 to 1766\n",
      "Data columns (total 16 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   file_name                     1767 non-null   object \n",
      " 1   building                      1767 non-null   int64  \n",
      " 2   meter                         1767 non-null   int64  \n",
      " 3   len_train                     1767 non-null   int64  \n",
      " 4   len_zero                      1767 non-null   int64  \n",
      " 5   per_data                      1767 non-null   float64\n",
      " 6   category                      1767 non-null   object \n",
      " 7   corr_meter_to_airtemp         1767 non-null   float64\n",
      " 8   corr_meter_to_airtemp_wknd    1766 non-null   float64\n",
      " 9   corr_meter_to_airtemp_wkdy    1767 non-null   float64\n",
      " 10  corr_meter_to_airtemp_winter  1767 non-null   float64\n",
      " 11  corr_meter_to_airtemp_spring  1755 non-null   float64\n",
      " 12  corr_meter_to_airtemp_summer  1759 non-null   float64\n",
      " 13  corr_meter_to_airtemp_fall    1763 non-null   float64\n",
      " 14  square_feet                   1767 non-null   int64  \n",
      " 15  floor_count                   1767 non-null   int64  \n",
      "dtypes: float64(8), int64(6), object(2)\n",
      "memory usage: 234.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_stats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "convinced-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling Choices\n",
    "# Buildings with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "understood-consultation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These represent buildings that are in top, mid and lower in square footage\n",
    "lrg = [869, 1148, 375, 365, 269]\n",
    "med = [1063, 1309, 991, 144, 693]\n",
    "sm = [846, 621, 822, 816, 44]\n",
    "\n",
    "bldgno = []\n",
    "bldgno.extend(lrg)\n",
    "bldgno.extend(med)\n",
    "bldgno.extend(sm)\n",
    "\n",
    "# 0: Electricity 1: chilledwater 2: steam 3: hotwater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "critical-hawaiian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>building</th>\n",
       "      <th>meter</th>\n",
       "      <th>len_train</th>\n",
       "      <th>len_zero</th>\n",
       "      <th>per_data</th>\n",
       "      <th>category</th>\n",
       "      <th>corr_meter_to_airtemp</th>\n",
       "      <th>corr_meter_to_airtemp_wknd</th>\n",
       "      <th>corr_meter_to_airtemp_wkdy</th>\n",
       "      <th>corr_meter_to_airtemp_winter</th>\n",
       "      <th>corr_meter_to_airtemp_spring</th>\n",
       "      <th>corr_meter_to_airtemp_summer</th>\n",
       "      <th>corr_meter_to_airtemp_fall</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>floor_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1148_1.pkl</td>\n",
       "      <td>1148</td>\n",
       "      <td>1</td>\n",
       "      <td>8784</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Office</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.76</td>\n",
       "      <td>861524</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name  building  meter  len_train  len_zero  per_data category  \\\n",
       "194  1148_1.pkl      1148      1       8784         0    100.00   Office   \n",
       "\n",
       "     corr_meter_to_airtemp  corr_meter_to_airtemp_wknd  \\\n",
       "194                   0.78                        0.79   \n",
       "\n",
       "     corr_meter_to_airtemp_wkdy  corr_meter_to_airtemp_winter  \\\n",
       "194                        0.79                          0.21   \n",
       "\n",
       "     corr_meter_to_airtemp_spring  corr_meter_to_airtemp_summer  \\\n",
       "194                          0.74                          0.45   \n",
       "\n",
       "     corr_meter_to_airtemp_fall  square_feet  floor_count  \n",
       "194                        0.76       861524           -1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats[(df_stats['building'] == 1148) & df_stats['meter'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "iraqi-original",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>building</th>\n",
       "      <th>meter</th>\n",
       "      <th>len_train</th>\n",
       "      <th>len_zero</th>\n",
       "      <th>per_data</th>\n",
       "      <th>category</th>\n",
       "      <th>corr_meter_to_airtemp</th>\n",
       "      <th>corr_meter_to_airtemp_wknd</th>\n",
       "      <th>corr_meter_to_airtemp_wkdy</th>\n",
       "      <th>corr_meter_to_airtemp_winter</th>\n",
       "      <th>corr_meter_to_airtemp_spring</th>\n",
       "      <th>corr_meter_to_airtemp_summer</th>\n",
       "      <th>corr_meter_to_airtemp_fall</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>floor_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1148_0.pkl</td>\n",
       "      <td>1148</td>\n",
       "      <td>0</td>\n",
       "      <td>8663</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Office</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>861524</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1148_1.pkl</td>\n",
       "      <td>1148</td>\n",
       "      <td>1</td>\n",
       "      <td>8784</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Office</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.76</td>\n",
       "      <td>861524</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>1148_2.pkl</td>\n",
       "      <td>1148</td>\n",
       "      <td>2</td>\n",
       "      <td>8784</td>\n",
       "      <td>2</td>\n",
       "      <td>99.98</td>\n",
       "      <td>Office</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>861524</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name  building  meter  len_train  len_zero  per_data category  \\\n",
       "193  1148_0.pkl      1148      0       8663         0    100.00   Office   \n",
       "194  1148_1.pkl      1148      1       8784         0    100.00   Office   \n",
       "902  1148_2.pkl      1148      2       8784         2     99.98   Office   \n",
       "\n",
       "     corr_meter_to_airtemp  corr_meter_to_airtemp_wknd  \\\n",
       "193                  -0.02                        0.15   \n",
       "194                   0.78                        0.79   \n",
       "902                  -0.88                       -0.86   \n",
       "\n",
       "     corr_meter_to_airtemp_wkdy  corr_meter_to_airtemp_winter  \\\n",
       "193                       -0.04                         -0.20   \n",
       "194                        0.79                          0.21   \n",
       "902                       -0.88                         -0.83   \n",
       "\n",
       "     corr_meter_to_airtemp_spring  corr_meter_to_airtemp_summer  \\\n",
       "193                         -0.11                         -0.08   \n",
       "194                          0.74                          0.45   \n",
       "902                         -0.85                         -0.43   \n",
       "\n",
       "     corr_meter_to_airtemp_fall  square_feet  floor_count  \n",
       "193                       -0.08       861524           -1  \n",
       "194                        0.76       861524           -1  \n",
       "902                       -0.44       861524           -1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine building choices\n",
    "df_stats[df_stats['building'] == 1148]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7ea794a-196f-419e-a940-04b31cdfae11",
   "metadata": {},
   "source": [
    "Notice that the 1 meter is positively correlated, 2 meter is strong negative correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-assessment",
   "metadata": {},
   "source": [
    "### Build list of files to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-recall",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get only the train data\n",
    "direct = glob.glob('.\\\\data_clean\\\\buildings_by_meter\\\\' + '*.pkl')\n",
    "\n",
    "directory = '.\\\\data_clean\\\\buildings_by_meter\\\\'\n",
    "ext = '.pkl'\n",
    "\n",
    "bld_mtr = ['1148_0','1148_1']\n",
    "files = []\n",
    "\n",
    "# Build File names\n",
    "for bm in bld_mtr:\n",
    "    file_n = directory + bm + ext\n",
    "    files.append(file_n)\n",
    "        \n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82d66d2-6c55-4f16-aa3c-365ff7148006",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "direct = '.\\\\data_clean\\\\buildings_by_meter\\\\'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-raise",
   "metadata": {},
   "source": [
    "# 1 - Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-equipment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 1148_0.pkl\n",
      "\n",
      "\n",
      "ARIMA Model...... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-29789a769377>:210: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_train.fillna(df_prophet_train.mean(), inplace=True)\n",
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prophet......\n",
      "\n",
      "\n",
      "XGBoost......\n",
      "File: 1148_1.pkl\n",
      "\n",
      "\n",
      "ARIMA Model...... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prophet......\n",
      "\n",
      "\n",
      "XGBoost......\n",
      "File: 869_0.pkl\n",
      "\n",
      "\n",
      "ARIMA Model...... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prophet......\n",
      "\n",
      "\n",
      "XGBoost......\n",
      "File: 846_0.pkl\n",
      "\n",
      "\n",
      "ARIMA Model...... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-29789a769377>:210: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_train.fillna(df_prophet_train.mean(), inplace=True)\n",
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prophet......\n",
      "\n",
      "\n",
      "XGBoost......\n",
      "File: 816_0.pkl\n",
      "\n",
      "\n",
      "ARIMA Model...... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-29789a769377>:210: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_train.fillna(df_prophet_train.mean(), inplace=True)\n",
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prophet......\n",
      "\n",
      "\n",
      "XGBoost......\n",
      "File: 693_0.pkl\n",
      "\n",
      "\n",
      "ARIMA Model...... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-29789a769377>:210: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_train.fillna(df_prophet_train.mean(), inplace=True)\n",
      "<ipython-input-50-29789a769377>:216: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_test.fillna(df_prophet_test.mean(), inplace=True)\n",
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prophet......\n",
      "\n",
      "\n",
      "XGBoost......\n",
      "File: 621_0.pkl\n",
      "\n",
      "\n",
      "ARIMA Model...... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-29789a769377>:210: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_train.fillna(df_prophet_train.mean(), inplace=True)\n",
      "<ipython-input-50-29789a769377>:216: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_test.fillna(df_prophet_test.mean(), inplace=True)\n",
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prophet......\n",
      "\n",
      "\n",
      "XGBoost......\n",
      "File: 375_0.pkl\n",
      "\n",
      "\n",
      "ARIMA Model...... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prophet......\n",
      "\n",
      "\n",
      "XGBoost......\n",
      "File: 144_0.pkl\n",
      "\n",
      "\n",
      "ARIMA Model...... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-29789a769377>:210: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_train.fillna(df_prophet_train.mean(), inplace=True)\n",
      "<ipython-input-50-29789a769377>:216: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_test.fillna(df_prophet_test.mean(), inplace=True)\n",
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prophet......\n",
      "\n",
      "\n",
      "XGBoost......\n",
      "File: 1148_2.pkl\n",
      "\n",
      "\n",
      "ARIMA Model...... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prophet......\n",
      "\n",
      "\n",
      "XGBoost......\n",
      "File: 365_0.pkl\n",
      "\n",
      "\n",
      "ARIMA Model...... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prophet......\n",
      "\n",
      "\n",
      "XGBoost......\n",
      "File: 1063_0.pkl\n",
      "\n",
      "\n",
      "ARIMA Model...... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prophet......\n",
      "\n",
      "\n",
      "XGBoost......\n",
      "File: 1309_1.pkl\n",
      "\n",
      "\n",
      "ARIMA Model...... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-29789a769377>:210: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_train.fillna(df_prophet_train.mean(), inplace=True)\n",
      "<ipython-input-50-29789a769377>:216: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_test.fillna(df_prophet_test.mean(), inplace=True)\n",
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prophet......\n",
      "\n",
      "\n",
      "XGBoost......\n",
      "File: 1309_0.pkl\n",
      "\n",
      "\n",
      "ARIMA Model...... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-29789a769377>:210: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_train.fillna(df_prophet_train.mean(), inplace=True)\n",
      "<ipython-input-50-29789a769377>:216: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_test.fillna(df_prophet_test.mean(), inplace=True)\n",
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prophet......\n",
      "\n",
      "\n",
      "XGBoost......\n",
      "File: 991_1.pkl\n",
      "\n",
      "\n",
      "ARIMA Model...... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-29789a769377>:210: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_train.fillna(df_prophet_train.mean(), inplace=True)\n",
      "<ipython-input-50-29789a769377>:216: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_test.fillna(df_prophet_test.mean(), inplace=True)\n",
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prophet......\n",
      "\n",
      "\n",
      "XGBoost......\n",
      "File: 991_0.pkl\n",
      "\n",
      "\n",
      "ARIMA Model...... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-29789a769377>:210: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_train.fillna(df_prophet_train.mean(), inplace=True)\n",
      "<ipython-input-50-29789a769377>:216: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_test.fillna(df_prophet_test.mean(), inplace=True)\n",
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prophet......\n",
      "\n",
      "\n",
      "XGBoost......\n",
      "File: 1309_2.pkl\n",
      "\n",
      "\n",
      "ARIMA Model...... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-29789a769377>:210: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_train.fillna(df_prophet_train.mean(), inplace=True)\n",
      "<ipython-input-50-29789a769377>:216: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df_prophet_test.fillna(df_prophet_test.mean(), inplace=True)\n",
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prophet......\n",
      "\n",
      "\n",
      "XGBoost......\n",
      "File: 822_0.pkl\n",
      "\n",
      "\n",
      "ARIMA Model...... "
     ]
    }
   ],
   "source": [
    "# Holes in the data\n",
    "# Data is daily\n",
    "offsets = [0] # offsets in days\n",
    "data_sizes = [120]\n",
    "test_sizes = [int(x * 0.25) for x in data_sizes]\n",
    "\n",
    "ARIMA = True\n",
    "FBProphet = True\n",
    "xgboost = True\n",
    "\n",
    "quiet_mode = True\n",
    "\n",
    "resample = True\n",
    "backfill = 'mean'\n",
    "exogen = True\n",
    "\n",
    "thresh = 50\n",
    "\n",
    "# For each of the file matches (did this way to prevent long run times)\n",
    "\n",
    "# Dictionary to hold all the results, will turn into a dataframe\n",
    "stats_all = {}\n",
    "stats_list = []\n",
    "\n",
    "# For each file in the directory\n",
    "direct = '.\\\\data_clean\\\\buildings_by_meter\\\\'\n",
    "\n",
    "files = df_stats['file_name']\n",
    "bl = df_stats['building']\n",
    "\n",
    "for num,file in enumerate(files):\n",
    "\n",
    "    # Termporary dictionary that represents a row\n",
    "    stats = {}\n",
    "    \n",
    "    # Skip if building not on our radar\n",
    "    if bl[num] not in bldgno:\n",
    "        continue\n",
    "    else:\n",
    "        print('File: ' + file)\n",
    "        df_train = pd.read_pickle(direct + file)\n",
    "     \n",
    "    # Load key variables in dictionary\n",
    "    stats['building_id'] = df_train.iloc[0]['building_id']\n",
    "    stats['square_feet'] = df_train.iloc[0]['square_feet']\n",
    "    \n",
    "    stats['meter'] = bldg_meter = df_train.iloc[0]['meter']\n",
    "    stats['file_path'] = file\n",
    "    \n",
    "    stats['category'] = df_stats[(df_stats['building'] == stats['building_id']) & (df_stats['meter'] == stats['meter'])]['category'].iloc[0]\n",
    "    stats['corr_meter_to_airtemp'] = df_stats[(df_stats['building'] == stats['building_id']) & (df_stats['meter'] == stats['meter'])]['corr_meter_to_airtemp'].iloc[0]    \n",
    "\n",
    "#     df_train = pd.get_dummies(df_train)\n",
    "#     print(df_train)\n",
    "    \n",
    "    # RESAMPLE DATA\n",
    "    if resample:\n",
    "        agg_dict={'meter_reading':'sum', \n",
    "                  'air_temperature':'max',\n",
    "                  'dew_temperature':'max',\n",
    "                  'cloud_coverage':'mean',\n",
    "                  'dew_temperature':'max',\n",
    "                  'precip_depth_1_hr':'sum',\n",
    "                  'sea_level_pressure':'mean',\n",
    "                  'building_id': 'max',\n",
    "                  'site_id': 'max',\n",
    "                  'square_feet': 'max',\n",
    "                  'day_of_week':'max',\n",
    "                  'weekend':'max',\n",
    "                  'month':'max',\n",
    "                  'season':'max'\n",
    "                  }\n",
    "\n",
    "        resamp = '1D'\n",
    "        \n",
    "        # Write Resample String\n",
    "        stats['resample_period'] = resamp\n",
    "\n",
    "        # Resample Dataframe\n",
    "        df_train = df_train.resample(resamp).agg(agg_dict)\n",
    "        \n",
    "        # Drops\n",
    "#         print(df_train.head())\n",
    "        \n",
    "    # Keep track of Models\n",
    "    model_ctr = 1\n",
    "    model_prefixes = []\n",
    "    \n",
    "    # Pull only training data\n",
    "    \n",
    "    # Curently for 4 periods data sizes is length, test_sizes is 0.25 % of that\n",
    "    for ds, ts in zip(data_sizes,test_sizes):     \n",
    "        for off in offsets:\n",
    "            # df_slice is the total size of the set\n",
    "            \n",
    "            df_slice = df_train.iloc[off:off+ds]\n",
    "            df_slice.drop(labels='sea_level_pressure',inplace=True,axis=1)\n",
    "            \n",
    "#             for column in df_slice.columns:\n",
    "#                 # Percent of data that is not zero\n",
    "#                 z_per = 100-((df_slice[column] == 0).sum()/len(df_slice[column])*100)\n",
    "#                 n_per = 100-((df_slice[column].isna()).sum()/len(df_slice[column])*100)\n",
    "                \n",
    "#             print(df_slice.count(axis=1))\n",
    "    \n",
    "            if ARIMA:\n",
    "                # Keep track of model prefix column names by building prefix to number iterations\n",
    "                model_prefix = 'Model_' + str(model_ctr)\n",
    "                model_prefixes.append(model_prefix)\n",
    "\n",
    "                #df_slice.dropna(inplace=True)\n",
    "                X_train, X_test, y_train, y_test = model_selection.train_test_split(df_slice.drop(labels=['meter_reading'],axis=1),\n",
    "                                                                                    df_slice['meter_reading'],test_size=ts)    \n",
    "                # Fill Nas\n",
    "                #Counts of null values \n",
    "                # Backfill with means\n",
    "                if np.max(X_train.isnull().sum().sort_values(ascending=False)) > 0:\n",
    "                    stats[model_prefix + '_' + 'X_train_Backfill'] = backfill\n",
    "                    if backfill == 'mean':\n",
    "                        X_train.fillna(X_train.mean(), inplace=True)\n",
    "\n",
    "                # Backfill with mean\n",
    "                if np.max(X_test.isnull().sum().sort_values(ascending=False)) > 0:\n",
    "                    stats[model_prefix + '_' + 'X_test_Backfill'] = backfill\n",
    "                    if backfill == 'mean':\n",
    "                        X_test.fillna(X_test.mean(), inplace=True)\n",
    "\n",
    "                # Get rid of constants\n",
    "                X_train.drop(labels=['site_id','building_id','square_feet'],axis=1,inplace=True)\n",
    "                X_test.drop(labels=['site_id','building_id','square_feet'],axis=1,inplace=True)\n",
    "\n",
    "                # Populate DataFrame with statistics\n",
    "                stats[model_prefix + '_' + 'Type'] = 'ARIMA_Exogen'\n",
    "                stats[model_prefix + '_' + 'DateStart'] = str(df_slice.iloc[0].name).split(\" \")[0]\n",
    "                stats[model_prefix + '_' + 'DateEnd'] = str(df_slice.iloc[-1].name).split(\" \")[0]\n",
    "                stats[model_prefix + '_' + 'DayOffset'] = off\n",
    "                stats[model_prefix + '_' + 'DataSize'] = ds\n",
    "                stats[model_prefix + '_' + 'TestSize'] = len(y_test)\n",
    "                stats[model_prefix + '_' + 'X_train_len'] = len(X_train)\n",
    "                stats[model_prefix + '_' + 'X_test_len'] = len(X_test)\n",
    "                stats[model_prefix + '_' + 'y_train_len'] = len(y_train)\n",
    "                stats[model_prefix + '_' + 'y_test_len'] = len(y_test)\n",
    "\n",
    "   #           ######################################    ARIMA   ##################################################\n",
    "                print(\"\\n\" * 1)\n",
    "                print('ARIMA Model......',end=' ')\n",
    "                \n",
    "                try:\n",
    "                    model = pm.auto_arima(y_train,X=X_train,trace=False,n_fits=10,seasonal=True,m=7,error_action='ignore')\n",
    "                    stats[model_prefix + '_' + 'Status'] = 'PASS'\n",
    "                except ValueError as ve:\n",
    "                    print('Model will not converge')\n",
    "                    stats[model_prefix + '_' + 'Status'] = 'FAIL'\n",
    "                    \n",
    "                    \n",
    "                preds, conf_int = model.predict(X=X_test,n_periods=y_test.shape[0], return_conf_int=True)\n",
    "\n",
    "                predict = pd.Series(preds,index=y_test.index)\n",
    "\n",
    "                # Keep each slice data here\n",
    "                df_result = pd.concat([predict,y_test],axis=1)\n",
    "                df_result.columns = ['meter_predict_ARIMA','meter_actual']\n",
    "\n",
    "                RMSE_error = (mean_squared_error(df_result['meter_predict_ARIMA'],df_result['meter_actual'],squared=False))\n",
    "\n",
    "                stats[model_prefix + '_' + 'RMSE'] = RMSE_error\n",
    "                stats[model_prefix + '_' + 'y_test_MAX'] = np.max(df_result['meter_actual'])\n",
    "                stats[model_prefix + '_' + 'y_test_MIN'] = np.min(df_result['meter_actual'])\n",
    "                stats[model_prefix + '_' + 'y_test_AVG'] = np.mean(df_result['meter_actual'])\n",
    "                \n",
    "                stats[model_prefix + '_' + 'y_pred_MAX'] = np.max(df_result['meter_predict_ARIMA'])\n",
    "                stats[model_prefix + '_' + 'y_pred_MIN'] = np.min(df_result['meter_predict_ARIMA'])\n",
    "                stats[model_prefix + '_' + 'y_pred_AVG'] = np.mean(df_result['meter_predict_ARIMA'])\n",
    "                \n",
    "                if not quiet_mode:\n",
    "                    # display\n",
    "                    plt.figure(figsize=(20,10))\n",
    "                    plt.plot(df_result['meter_predict_ARIMA'],label=\"ARIMA\")\n",
    "                    plt.plot(df_result['meter_actual'],label=\"Actual\")\n",
    "                    plt.legend(loc = 'upper right')\n",
    "                    plt.savefig('SecondPrection.jpg')\n",
    "                    plt.show()\n",
    "                    \n",
    "                    print('RMSE: ' + str(RMSE_error))\n",
    "                    \n",
    "\n",
    "\n",
    "            \n",
    "            ######################################    PROPHET   ##################################################\n",
    "            if FBProphet:\n",
    "                print(\"\\n\" * 1)\n",
    "                print('Prophet......')\n",
    "                model_ctr += 1\n",
    "                model_prefix = 'Model_' + str(model_ctr)\n",
    "                model_prefixes.append(model_prefix)\n",
    "\n",
    "                # Prophet keeps target variable with regressors\n",
    "                df_train, df_test = model_selection.train_test_split(df_slice,test_size=ts)\n",
    "\n",
    "                # Need renaming for Prophet - data prep\n",
    "                df_prophet_train = df_train.reset_index()\n",
    "                df_prophet_test = df_test.reset_index()\n",
    "\n",
    "                # Fill Nas\n",
    "                #Counts of null values \n",
    "                # Backfill with means\n",
    "                if np.max(df_prophet_train.isnull().sum().sort_values(ascending=False)) > 0:\n",
    "                    stats[model_prefix + '_' + 'train_Backfill'] = backfill\n",
    "                    if backfill == 'mean':\n",
    "                        df_prophet_train.fillna(df_prophet_train.mean(), inplace=True)\n",
    "\n",
    "                # Backfill with mean\n",
    "                if np.max(df_prophet_test.isnull().sum().sort_values(ascending=False)) > 0:\n",
    "                    stats[model_prefix + '_' + 'test_Backfill'] = backfill\n",
    "                    if backfill == 'mean':\n",
    "                        df_prophet_test.fillna(df_prophet_test.mean(), inplace=True)\n",
    "\n",
    "\n",
    "                # Timestamp must be ds column\n",
    "                df_prophet_train = df_prophet_train.rename(columns={'timestamp':'ds','meter_reading':'y'})\n",
    "                df_prophet_test = df_prophet_test.rename(columns={'timestamp':'ds','meter_reading':'y'})\n",
    "\n",
    "\n",
    "                stats[model_prefix + '_' + 'Type'] = 'Prophet_Exogen'\n",
    "                stats[model_prefix + '_' + 'DateStart'] = str(df_prophet_train.iloc[0]['ds']).split(\" \")[0]\n",
    "                stats[model_prefix + '_' + 'DateEnd'] = str(df_prophet_train.iloc[-1]['ds']).split(\" \")[0]\n",
    "                stats[model_prefix + '_' + 'DayOffset'] = off\n",
    "                stats[model_prefix + '_' + 'DataSize'] = ds\n",
    "                stats[model_prefix + '_' + 'Train_len'] = len(df_prophet_train)\n",
    "                stats[model_prefix + '_' + 'Test_len'] = len(df_prophet_test)\n",
    "    #           print(df_prophet_train)\n",
    "\n",
    "                m = Prophet(daily_seasonality=True)\n",
    "                m.add_regressor('air_temperature')\n",
    "                m.add_regressor('dew_temperature')\n",
    "                m.add_regressor('cloud_coverage')\n",
    "                m.add_regressor('precip_depth_1_hr')\n",
    "                m.add_regressor('day_of_week')\n",
    "                m.add_regressor('weekend')\n",
    "                m.add_regressor('month')\n",
    "                m.add_regressor('season')\n",
    "                m.fit(df_prophet_train)\n",
    "                predicts = m.predict(df_prophet_test)\n",
    "\n",
    "                RMSE_error = (mean_squared_error(predicts['yhat'],df_prophet_test['y'],squared=False))\n",
    "\n",
    "                stats[model_prefix + '_' + 'RMSE'] = RMSE_error\n",
    "                stats[model_prefix + '_' + 'y_test_MAX'] = np.max(df_prophet_test['y'])\n",
    "                stats[model_prefix + '_' + 'y_test_MIN'] = np.min(df_prophet_test['y'])\n",
    "                stats[model_prefix + '_' + 'y_test_AVG'] = np.mean(df_prophet_test['y'])\n",
    "                \n",
    "                stats[model_prefix + '_' + 'y_pred_MAX'] = np.max(predicts['yhat'])\n",
    "                stats[model_prefix + '_' + 'y_pred_MIN'] = np.min(predicts['yhat'])\n",
    "                stats[model_prefix + '_' + 'y_pred_AVG'] = np.mean(predicts['yhat'])\n",
    "\n",
    "                if not quiet_mode:\n",
    "                    plt.figure(figsize=(20,10))\n",
    "                    plt.plot(predicts['yhat'],label=\"Prophet\")\n",
    "                    plt.plot(df_prophet_test['y'],label=\"Actual\")\n",
    "                    plt.legend(loc = 'upper right')\n",
    "                    plt.show()\n",
    "                    print('RMSE: ' + str(RMSE_error))\n",
    "                    stats[model_prefix + '_' + 'Status'] = 'PASS'\n",
    "     \n",
    "            ######################################    XGBOOST   ##################################################\n",
    "            if xgboost:\n",
    "                print(\"\\n\" * 1)\n",
    "                print('XGBoost......')\n",
    "                model_ctr += 1\n",
    "                model_prefix = 'Model_' + str(model_ctr)\n",
    "                model_prefixes.append(model_prefix)\n",
    "                \n",
    "                # split data into X and y\n",
    "                X = df_slice.drop('meter_reading', axis=1)\n",
    "                y = df_slice[['meter_reading']]\n",
    "                \n",
    "                # Fill Nas\n",
    "                #Counts of null values \n",
    "                # Backfill with means\n",
    "                if np.max(X.isnull().sum().sort_values(ascending=False)) > 0:\n",
    "                    stats[model_prefix + '_' + 'train_Backfill'] = backfill\n",
    "                    X.fillna(X.median(), inplace=True)\n",
    "\n",
    "                # Train Test Split\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ts)\n",
    "                        \n",
    "                stats[model_prefix + '_' + 'Type'] = 'XGBoost'\n",
    "                stats[model_prefix + '_' + 'DateStart'] = str(df_slice.iloc[0].name).split(\" \")[0]\n",
    "                stats[model_prefix + '_' + 'DateEnd'] = str(df_slice.iloc[-1].name).split(\" \")[0]\n",
    "                stats[model_prefix + '_' + 'DayOffset'] = off\n",
    "                stats[model_prefix + '_' + 'DataSize'] = ds\n",
    "                stats[model_prefix + '_' + 'Train_len'] = len(X_train)\n",
    "                stats[model_prefix + '_' + 'Test_len'] = len(X_test)\n",
    "                \n",
    "                \n",
    "#                 # Instantiate Model\n",
    "                gbm_model = xgb.XGBRegressor(objective = 'reg:squarederror', n_estimators = 1000, seed = 123)\n",
    "                gbm_model.fit(X_train,y_train)\n",
    "                predict = gbm_model.predict(X_test)\n",
    "                \n",
    "                predict = pd.Series(predict,index=y_test.index)\n",
    "                \n",
    "                df_result = pd.concat([predict,y_test],axis=1,ignore_index=True)\n",
    "                df_result.columns = ['meter_predict_XGBoost','meter_actual']\n",
    "                df_result.sort_index(inplace=True)\n",
    "                \n",
    "                \n",
    "                RMSE_error = (mean_squared_error(predict,y_test,squared=False))\n",
    "\n",
    "                stats[model_prefix + '_' + 'RMSE'] = RMSE_error\n",
    "                stats[model_prefix + '_' + 'y_test_MAX'] = np.max(y_test)\n",
    "                stats[model_prefix + '_' + 'y_test_MIN'] = np.min(y_test)\n",
    "                stats[model_prefix + '_' + 'y_test_AVG'] = np.mean(y_test)\n",
    "                \n",
    "                stats[model_prefix + '_' + 'y_pred_MAX'] = np.max(predict)\n",
    "                stats[model_prefix + '_' + 'y_pred_MIN'] = np.min(predict)\n",
    "                stats[model_prefix + '_' + 'y_pred_AVG'] = np.mean(predict)\n",
    "                \n",
    "                if not quiet_mode:\n",
    "                    plt.figure(figsize=(20,10))\n",
    "                    plt.plot(df_result['meter_predict_XGBoost'],label=\"XGBoost\")\n",
    "                    plt.plot(df_result['meter_actual'],label=\"Actual\")\n",
    "                    plt.legend(loc = 'upper right')\n",
    "                    plt.show()\n",
    "                    print('RMSE: ' + str(RMSE_error))\n",
    "                    \n",
    "    stats_list.append(stats)\n",
    "#     pp.pprint(stats)\n",
    "df_results = pd.DataFrame(stats_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "955f7ae0-b0af-43e4-801a-6f4ab5dcd91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_1_RMSE</th>\n",
       "      <th>Model_2_RMSE</th>\n",
       "      <th>Model_3_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6098.68</td>\n",
       "      <td>2783.18</td>\n",
       "      <td>3473.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13750.16</td>\n",
       "      <td>13760.47</td>\n",
       "      <td>1617.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11795.41</td>\n",
       "      <td>13574.35</td>\n",
       "      <td>11780.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.62</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.31</td>\n",
       "      <td>17.01</td>\n",
       "      <td>23.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1030.68</td>\n",
       "      <td>1038.47</td>\n",
       "      <td>1273.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>63.62</td>\n",
       "      <td>59.14</td>\n",
       "      <td>41.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7083.21</td>\n",
       "      <td>4946.11</td>\n",
       "      <td>2733.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>125.29</td>\n",
       "      <td>508.63</td>\n",
       "      <td>249.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>162528.99</td>\n",
       "      <td>129578.94</td>\n",
       "      <td>100954.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15879.08</td>\n",
       "      <td>8447.02</td>\n",
       "      <td>5199.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>268.47</td>\n",
       "      <td>277.61</td>\n",
       "      <td>308.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1910.49</td>\n",
       "      <td>1786.74</td>\n",
       "      <td>682.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>267.37</td>\n",
       "      <td>159.02</td>\n",
       "      <td>216.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>674.21</td>\n",
       "      <td>675.84</td>\n",
       "      <td>288.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>249.40</td>\n",
       "      <td>212.98</td>\n",
       "      <td>257.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3388.80</td>\n",
       "      <td>2123.81</td>\n",
       "      <td>2745.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12.32</td>\n",
       "      <td>11.94</td>\n",
       "      <td>11.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model_1_RMSE  Model_2_RMSE  Model_3_RMSE\n",
       "0        6098.68       2783.18       3473.27\n",
       "1       13750.16      13760.47       1617.94\n",
       "2       11795.41      13574.35      11780.61\n",
       "3           2.62          2.50          3.52\n",
       "4          18.31         17.01         23.33\n",
       "5        1030.68       1038.47       1273.16\n",
       "6          63.62         59.14         41.90\n",
       "7        7083.21       4946.11       2733.24\n",
       "8         125.29        508.63        249.61\n",
       "9      162528.99     129578.94     100954.64\n",
       "10      15879.08       8447.02       5199.44\n",
       "11        268.47        277.61        308.09\n",
       "12       1910.49       1786.74        682.99\n",
       "13        267.37        159.02        216.25\n",
       "14        674.21        675.84        288.75\n",
       "15        249.40        212.98        257.44\n",
       "16       3388.80       2123.81       2745.26\n",
       "17         12.32         11.94         11.52"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d249abe1-7015-471c-a74d-3383cec252e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'concat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-3ee7127327db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_stats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\cap1\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'concat'"
     ]
    }
   ],
   "source": [
    "df_stats = df_stats.merge(df_results,how='left',on=['site_id','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f65011d7-88fe-494d-b696-cc46fff95125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>building</th>\n",
       "      <th>meter</th>\n",
       "      <th>len_train</th>\n",
       "      <th>len_zero</th>\n",
       "      <th>per_data</th>\n",
       "      <th>category</th>\n",
       "      <th>corr_meter_to_airtemp</th>\n",
       "      <th>corr_meter_to_airtemp_wknd</th>\n",
       "      <th>corr_meter_to_airtemp_wkdy</th>\n",
       "      <th>corr_meter_to_airtemp_winter</th>\n",
       "      <th>corr_meter_to_airtemp_spring</th>\n",
       "      <th>corr_meter_to_airtemp_summer</th>\n",
       "      <th>corr_meter_to_airtemp_fall</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>floor_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>693_0.pkl</td>\n",
       "      <td>693</td>\n",
       "      <td>0</td>\n",
       "      <td>8784</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Office</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>57436</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_name  building  meter  len_train  len_zero  per_data category  \\\n",
       "388  693_0.pkl       693      0       8784         0    100.00   Office   \n",
       "\n",
       "     corr_meter_to_airtemp  corr_meter_to_airtemp_wknd  \\\n",
       "388                  -0.15                       -0.13   \n",
       "\n",
       "     corr_meter_to_airtemp_wkdy  corr_meter_to_airtemp_winter  \\\n",
       "388                       -0.16                          0.06   \n",
       "\n",
       "     corr_meter_to_airtemp_spring  corr_meter_to_airtemp_summer  \\\n",
       "388                         -0.14                          0.37   \n",
       "\n",
       "     corr_meter_to_airtemp_fall  square_feet  floor_count  \n",
       "388                       -0.08        57436            3  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats[(df_stats['building'] == 693)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-geography",
   "metadata": {},
   "source": [
    "# 2 - Build Model - Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-villa",
   "metadata": {},
   "source": [
    "## Time Series Split Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-sauce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tss =  TimeSeriesSplit(n_splits=4,gap=4,test_size=14,max_train_size=120) #too generic\n",
    "rmse = []\n",
    "count = 1\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Write function that rolls next pd.delta?\n",
    "\n",
    "for train_index, test_index in tss.split(df_train): \n",
    "    \n",
    "    cv_train, cv_test = df_train.iloc[train_index]['meter_reading'], df_train.iloc[test_index]['meter_reading']\n",
    "    model = pm.auto_arima(cv_train,trace=True,n_fits=20)\n",
    "    print(model.summary())\n",
    "    \n",
    "    # \n",
    "    predicts = model.predict(n_periods=14)\n",
    "    true_values = cv_test.values\n",
    "    error = ((sqrt(mean_squared_error(predicts,true_values))))\n",
    "    model.plot_diagnostics()\n",
    "    rmse.append(error)\n",
    "    print(error)\n",
    "print('RMSE')\n",
    "print(np.mean(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tyra\n",
    "print(model.summary())\n",
    "\n",
    "# \n",
    "predicts = model.predict(n_periods=14)\n",
    "true_values = cv_test.values\n",
    "error = ((sqrt(mean_squared_error(predicts,true_values))))\n",
    "model.plot_diagnostics()\n",
    "rmse.append(error)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-confidence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-butler",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(n_periods=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-architect",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#                      start_p=1,max_p=7,\n",
    "#                      start_q=1,max_q=7,\n",
    "#                      start_P=1,max_P=7,\n",
    "#                      start_Q=1,max_Q=7,\n",
    "preds = model.predict(n_periods=test.shape[0], return_conf_int=False)\n",
    "\n",
    "# cv = model_selection.SlidingWindowForecastCV(window_size=3,step=1,h=4)\n",
    "# predictions = model_selection.cross_val_predict(model, test, cv=cv, verbose=2, averaging='median')\n",
    "# # temp_model_cv_scores = model_selection.cross_val_score(model, train, scoring='smape', cv=cv, verbose=2)\n",
    "\n",
    "# pred = pd.Series(predictions)\n",
    "# df_temp_preds = pd.DataFrame(pred,index=test.index,columns=['predictions'])\n",
    "# df_preds =pd.concat([df_temp_preds,test],axis=1)\n",
    "# df_preds\n",
    "\n",
    "# Print the error:\n",
    "print(\"Test RMSE: %.3f\" % np.sqrt(mean_squared_error(test, preds)))\n",
    "\n",
    "\n",
    "# Plot Forecasts\n",
    "x_axis = np.arange(train.shape[0] + preds.shape[0])\n",
    "x_years = x_axis + 2016  # Year starts at 1821\n",
    "\n",
    "plt.plot(preds,kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.plot_diagnostics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_preds = pd.DataFrame(preds,index=test.index,columns=['predictions'])\n",
    "df_preds =pd.concat([df_temp_preds,test],axis=1)\n",
    "df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Forecasts\n",
    "x_axis = np.arange(train.shape[0] + preds.shape[0])\n",
    "x_years = x_axis + 2016  # Year starts at 1821\n",
    "\n",
    "plt.plot(df_preds,kind='line')\n",
    "\n",
    "# plt.fill_between(x_years[x_axis[-preds.shape[0]:]],\n",
    "#                  conf_int[:, 0], conf_int[:, 1],\n",
    "#                  alpha=0.1, color='b')\n",
    "# plt.title(\"Temperature Forecast\")\n",
    "# plt.xlabel(\"Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-hands",
   "metadata": {},
   "source": [
    "# ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-peter",
   "metadata": {},
   "source": [
    "### Set PDQ"
   ]
  },
  {
   "cell_type": "raw",
   "id": "appreciated-concentrate",
   "metadata": {},
   "source": [
    "p = 5 # lag observations\n",
    "d = 1 # Raw Observations Differenced\n",
    "q = 0 # Moving Average Window"
   ]
  },
  {
   "cell_type": "raw",
   "id": "continuing-nowhere",
   "metadata": {},
   "source": [
    "# Brownlee page 221 (GP BOOK page 224)\n",
    "\n",
    "model = ARIMA(df_train['meter_reading'],order=(p,d,q))\n",
    "model_fit = model.fit()\n",
    "print(model_fit.summary())\n",
    "residuals = pd.DataFrame(model_fit.resid)\n",
    "residuals.plot()\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "attempted-seeking",
   "metadata": {},
   "source": [
    "residuals.plot(kind='kde')\n",
    "pyplot.show()\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-terminology",
   "metadata": {},
   "source": [
    "# Rolling Forecast ARIMA\n",
    "### Walk-forward validation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "neutral-algeria",
   "metadata": {},
   "source": [
    "### Split train / test\n",
    "\n",
    "data_len = 366\n",
    "split_test_doy = 270\n",
    "\n",
    "df_train = df.iloc[0:split_test_doy]\n",
    "df_test = df.iloc[split_test_doy:data_len]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "oriented-current",
   "metadata": {},
   "source": [
    "# Brownlee Time Series Forecasting with Python pg216 (GP Book 229)\n",
    "history = [x for x in df_train['meter_reading'].values]\n",
    "predicted_vals = [] # New predicted value list\n",
    "\n",
    "# Step through each meter reading\n",
    "for t in range(len(df_test['meter_reading'])):\n",
    "    model = ARIMA(history, order=(p,d,q))\n",
    "    model_fit = model.fit()\n",
    "    output = model_fit.forecast(7)\n",
    "    yhat = output[6]\n",
    "    print(len(output))\n",
    "    predicted_vals.append(yhat)\n",
    "    observation = df_test['meter_reading'].iloc[t]\n",
    "    history.append(observation)\n",
    "\n",
    "   # Show every 5 days\n",
    "\n",
    "    print('Iteration: ' + str(t) + ' Date: ' + str(df_test.index[t]),end=\" \")\n",
    "    print('Predicted Meter Reading = %f, Expected Meter Reading = %f' % (yhat,observation))\n",
    "\n",
    "rmse = sqrt(mean_squared_error(df_test['meter_reading'], predicted_vals))\n",
    "print('p = ' + str(p) + ' d = ' + str(d) + ' q = ' + str(q))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "df_predict = pd.DataFrame(predicted_vals,index=df_test.index,columns=['meter_predict'])\n",
    "\n",
    "pyplot.plot(df_test['meter_reading'])\n",
    "pyplot.plot(df_predict['meter_predict'], color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-saying",
   "metadata": {},
   "source": [
    "### Grid Search ARIMA / Evaluation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "municipal-transcript",
   "metadata": {},
   "source": [
    "# Brownlee Time Series Forecasting pg 225 (GP 238)\n",
    "def eval_ARIMA_model(series,split_index,arima_order):\n",
    "    orig_len = len(series) # Find total length\n",
    "    \n",
    "    ser_train = series.iloc[0:split_index] # Split train\n",
    "    ser_test = series.iloc[split_index:orig_len] # Split\n",
    "\n",
    "    history = [x for x in ser_train.values]\n",
    "    predicted_vals = []\n",
    "    \n",
    "    for t in range(len(ser_test)):\n",
    "        model = ARIMA(history,order=arima_order)\n",
    "        model_fit =  model.fit()\n",
    "        yhat = model_fit.forecast()[0]\n",
    "        predicted_vals.append(yhat)\n",
    "        history.append(ser_test.iloc[t])\n",
    "    rmse = sqrt(mean_squared_error(ser_test,predicted_vals))\n",
    "    return rsme \n",
    "\n",
    "# Brownlee Time Series Forecasting with Python\n",
    "def evaluate_models(series,split_index,p_vals,df_vals,q_vals):\n",
    "    series = series.astype('float32')\n",
    "    best_score, best_cfg = float('inf'), None\n",
    "    for p in p_vals:\n",
    "        for d in d_vals:\n",
    "            for q in q_vals:\n",
    "                order = (p,d,q)\n",
    "                try:\n",
    "                    rmse = eval_ARIMA_model(series,split_index,order)\n",
    "                    print(str(p,d,q) + ' Current RSME = ' + str(rsme))\n",
    "                    if rmse < best_score:\n",
    "                        best_score, best_cfg = rmse, order\n",
    "                    print('ARIMA %s RMSE=%.3f' % (order, rmse))\n",
    "                except:\n",
    "                    continue\n",
    "    print('Best ARIMA %s RMSE=%.3f' % (best_cfg, best_score))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eligible-preliminary",
   "metadata": {},
   "source": [
    "import warnings\n",
    "\n",
    "### Split train / test\n",
    "split_test_index = 270\n",
    "order = 1\n",
    "\n",
    "p_vals = [2]\n",
    "d_vals = [1]\n",
    "q_vals = [1]\n",
    "\n",
    "evaluate_models(df['meter_reading'],split_test_index, p_vals,d_vals,q_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-navigator",
   "metadata": {},
   "source": [
    "# Facebook Prophet\n",
    "## Additive Time Series Forecasting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_len = 366\n",
    "split_test_doy = 270\n",
    "\n",
    "df_train = df.iloc[0:split_test_doy]\n",
    "df_test = df.iloc[split_test_doy:data_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prophet_train = df_train.reset_index()\n",
    "df_prophet_train = df_prophet_train[['timestamp','meter_reading']]\n",
    "df_prophet_train = df_prophet_train.rename(columns={'timestamp':'ds','meter_reading':'y'})\n",
    "\n",
    "df_prophet_test = df_test.reset_index()\n",
    "df_prophet_test = df_prophet_test[['timestamp','meter_reading']]\n",
    "df_prophet_test = df_prophet_test.rename(columns={'timestamp':'ds','meter_reading':'y'})\n",
    "\n",
    "df_prophet_predict = df_test.reset_index()\n",
    "df_prophet_predict = df_prophet_predict[['timestamp']]\n",
    "df_prophet_predict = df_prophet_predict.rename(columns={'timestamp':'ds'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Prophet()\n",
    "model.fit(df_prophet_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast = model.predict(df_prophet_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-cruise",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone",
   "language": "python",
   "name": "cap1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
